{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider that we have classification problem like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb9d01fadf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter([1,2],[1,2],color = \"green\",label = \"okey\")\n",
    "plt.scatter([3,4],[3,4], color = \"red\", label = \"not okey\")\n",
    "plt.xlabel(\"index\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model should predict the labels as okey or not okey. While predicting the labels, it will be predicting likelihood. Lets asume that the model estimate them like below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $P(x;w)$ is the probabilty of okey and $P'(x;w)$ is the probabilty of not okey.\n",
    "- $P_{index=1}(x;w) = 0.9$ \n",
    "- $P_{index=2}(x;w) = 0.6$  \n",
    "- $P'_{index=3}(x;w) = 0.7$\n",
    "- $P'_{index=4}(x;w) = 0.9$    \n",
    "\n",
    "For green points, being close to (0,0) is more likely for P(x) and for red point being close to (4,4) is more likely for P'(x)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to calculate the success of classifying all points of the model, we must calculate the probability of correctness of all predictions. These are discreate events, so we should multiply the probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4536"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "0.9*0.8*0.7*0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets assume that the model is not good. The predictions are 0.1 0.2 0.3 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015000000000000002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "0.1*0.2*0.3*0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets assume that we made more then 4 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = 0.2\n",
    "for _ in range(20):\n",
    "    x = x*x\n",
    "\n",
    "x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accualy the result is not 0 but python cast it to 0. We have talked about this, poor condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product does not work well for the numbers between [0,1) We can turn products into sums with logarithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.502290170873972"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "p = [0.2,0.3,0.25]\n",
    "x = math.log(0.1)\n",
    "for i in p:\n",
    "    x = x + math.log(i)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got negative number, lets convert it to positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.502290170873972"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = [0.2,0.3,0.25]\n",
    "x = -math.log(0.1)\n",
    "for i in p:\n",
    "    x = x - math.log(i)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For low probabilites, we got 6.50, what would happen if the model is good and probabilites are high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1960046346767592"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = [0.7,0.9,0.8]\n",
    "x = -math.log(0.6)\n",
    "for i in p:\n",
    "    x = x - math.log(i)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got smaller number, for model accuracy we can descent the cross entropy. We assign the probabilites as P and P' but we got just 1 result. We can generalize it like:\n",
    "\n",
    "- Cross-Entropy = $-\\sum y_{i}ln(p_{i}) + (1-y_{i})ln(1-p_{i})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would happen if we have more then 2 classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding new term form every class is absurd. The formula becomes:\n",
    "- MultiClass-Cross-Entropy = $-\\sum_{i}^{n}\\sum_{j}^{m}y_{ij}ln(p_{ij})$\n",
    "\n",
    "If we apply it for 2 classes, we can see that Cross-Entropy and MultiClass-Cross-Entropy formulas are same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Imagine that you are a data scientist working at a casino.Casino has a game that there is a tricky coin, it has the number 1 in front and the number 0 behind it. Cause of Corona the casino was closed for 3 years , after Turkish scientist from Yıldız Technical University found the vaccine, it was decided that the casino would be opening. The gambler quit the work and no one knows which side of the coin is making money to the casino.\n",
    "\n",
    "    Casino built a system to find out that.The game is played autonomously and it takes a picture of which side of the coin came as a result of the game.First,photographer tried to seperate them. There were many images that a person can not figure out which side of the coin is making money to the casino. So we have some photos labelled and unlabelled.\n",
    "\n",
    "    As a data scientist, you must build a model to solve this problem. Lets begin ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, lets begin reading labelled images. We need to import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"C:/Users/bilgisayar/Desktop/Ml_implementations/Intro2ML/data/mnist/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(path/\"zeros/1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x269b7616da0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice !!! We have access photos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Know lets think what we can do to classify these photos ? If we average all pixels of all images, we can evaluate images that we will classify as 0 or 1.\n",
    "\n",
    "So we need to avarage all images each of class 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(path.iterdir())\n",
    "Path.ls = lambda x: list(x.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros =[torch.tensor(np.array(Image.open(img)), dtype = torch.float32) for img in (path/\"zeros\").ls()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones =[torch.tensor(np.array(Image.open(img)), dtype = torch.float32) for img in (path/\"ones\").ls()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(zeros[0], cmap = \"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_stack,ones_stack = torch.stack(zeros)  , torch.stack(ones) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5923, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6742, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_avg= zeros_stack.mean(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_avg = ones_stack.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x269b89cf9b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(zeros_avg , cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x269b78dfac8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ones_avg , cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we have mean.Lets find a loss function that when we decrase the loss evalation metric will be increasing. What would happen if we meausere the euclidian distance between avarage and images we want to classify ? Lets try and see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(avg,real):\n",
    "    return ((avg -real)**2).mean((-1,-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2299.9585)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(zeros_avg,zeros[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7474.8770)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(ones_avg,zeros[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss should be small. If the distance is high this means our image doesn't look like avarage. We can do some simple comparison. Calculate loss for both class and choose that the small one.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_class(img):\n",
    "    return 0 if loss(zeros_avg,img)<loss(ones_avg,img) else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which_class(zeros[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which_class(ones[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, that is working, lets look at how many of them correctly classify by our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(zeros,ones):\n",
    "    return float(((loss(zeros_avg,zeros)<loss(ones_avg,zeros)).sum() +  (loss(zeros_avg,ones)>loss(ones_avg,ones)).sum()))/(len(ones)+len(zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9920252664824319"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(zeros_stack,ones_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incredible !!!! I have never experienced reaching 99 percent of accuary until now with any neural network architecture. But there is a little problem here. We train our model with whole data and test it on same data. This is wrong. We do not know what would happen if we tested the model on it did not interact? Lets split the dataset on see what is will happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_split(data,val_per):\n",
    "    \n",
    "    indices = torch.randperm(len(data))\n",
    "    train = data[int(np.floor(len(data)*val_per/100)):]\n",
    "    validation = data[:int(np.floor(len(data)*val_per/100))]\n",
    "\n",
    "    return train,validation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainzero,validationzero = train_validation_split(zeros_stack,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2962, 28, 28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainzero.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2961, 28, 28])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validationzero.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainone , validationone = train_validation_split(ones_stack,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_avg= trainzero.mean(0) \n",
    "ones_avg = trainone.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9930511686670878"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(validationzero,validationone)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unexpectedly it increased !!! I would say \"What can we do to icrease the accuracy?\" if it was low. But we should not stop here. Maybe we can find a better way. The pixel values our information sources about the class of image. Every single pixel has a different meaning and some pixels are more important. We should highlight the important pixels for our model. We can add weight to important pixels. How can we know that which pixel is important ? Maybe we should add weight to all pixels and then we can do some changes on weights. Maybe we can devolop an algorithm to optimize weights. Lets go on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our images has 28*28 = 784 pixels so we need 784 weights. Then add a bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn((784,1), dtype=torch.float32)\n",
    "bias = torch.randn(1, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.cat((trainzero,trainone),0).view(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6333, 784])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets multiple the weights with the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple(weights,pixels):\n",
    "    return pixels@weights+bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6332, 784])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = torch.cat((validationzero,validationone),0).view(-1,28*28)\n",
    "validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6332, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = multiple(w,validation)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3095.8335])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have only one value for each image. How can we classify images by using this number ? If this values make sense about classifying, then we can choose a pivot value and if the value smaller than pivot, we say that the class of that image is bla bla... Lets look at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = 50 \n",
    "def accuracy(validation,ci):\n",
    "    return float(((prediction[:ci]<pivot).sum() +  (prediction[ci:]>pivot).sum()))/len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48404927353126975"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(validation,len(validationzero))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":) accuracy is fifty percent like flipping coin not tricky one :d. Cause of random weights, we get this result.If we optimize the parameters, then we can reach a good result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48404927353126975"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[0] = w[0]*2\n",
    "accuracy(validation,len(validationzero))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above, the accuracy can not be used for optimizing weight parameters because when we change one of weights,we can not see any changes on the result of our metric. For optimizing parameters we can not use accuracy metic and need a new one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one problem about our range. -infinity and +infinity range has a really large scale. We are calculating probiblty,0-1. If we find a function,then we can set our range [0,1].Our value is X. X/(X+1) looks good because when x goes to +infinity the result is 1. When x == 0 the result is 0. But if x == -1, that is a problem but function is good. X should not take - values. Then we need a function always positive. Exponential works. exp(X)/exp(X)+1 is a great function. Accualy this function has a special name, sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(prediction[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(prediction):\n",
    "    prediction = prediction.sigmoid()\n",
    "    return (prediction[:len(trainzero)].sum() + (1-prediction[len(trainzero):]).sum())/len(train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5143)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we optimize the parameters ? We have a loss function that we want to decrease. We need to find the global minimum of that function.If we take derivative of function and then go to opposite direction then we decrase our loss function. This called as gradient descent. We wiil use Pytorch to take derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will discover a new architecture. We manually initialized weights,bias and developed a model, but pure python is really slow. Matrix multiplication is not the best thing python does.Lets do all things with Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "model = nn.Sequential(nn.Linear(784,1),\n",
    "                     nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4193, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label0 = np.zeros(len(trainzero))\n",
    "label1 = np.ones(len(trainone))\n",
    "target = np.concatenate((label0, label1))\n",
    "target =torch.tensor(target).float().view((6333,1))\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.SGD(model.parameters(),lr = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "epoch = 50\n",
    "for i in range(epoch):\n",
    "    prediction = model(train)\n",
    "    lossfnc = loss(prediction,target)\n",
    "    optimizer.zero_grad()\n",
    "    lossfnc.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0085, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(prediction,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9913153323859151"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot = 0.5\n",
    "accuracy(validation,len(validationzero))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the results looks same, our baseline model (avarage) is better solution for this task because it is easy to implement and time complexity is a bigger problem for our simple neural network architecture."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
